# BM25

Sparse retrieval based on term frequency.

## Overview

| Field | Value |
|-------|-------|
| Type | Retrieval |
| Algorithm | TF-IDF variant |
| Modality | Text |
| Paper | [Robertson & Zaragoza, 2009](https://www.nowpublishers.com/article/Details/INR-019) |

## How It Works

Ranks documents by:

1. Term frequency in document
2. Inverse document frequency
3. Document length normalization

Uses VectorChord-BM25 PostgreSQL extension for efficient full-text search.

## Configuration

```yaml
_target_: autorag_research.pipelines.retrieval.bm25.BM25PipelineConfig
name: bm25
tokenizer: bert
top_k: 10
batch_size: 100
```

## Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| name | str | required | Unique pipeline instance name |
| tokenizer | str | `bert` | Tokenization method |
| index_name | str | `idx_chunk_bm25` | BM25 index name in PostgreSQL |
| top_k | int | 10 | Results per query |
| batch_size | int | 100 | Queries per batch |

## Tokenizers

| Tokenizer | Description |
|-----------|-------------|
| bert | BERT WordPiece |
| wiki_tocken | Wikipedia-based |
| gemma2b | Gemma 2B model |
| llmlingua2 | LLMLingua2 |

## When to Use

Good for:

- Keyword queries
- Exact term matching
- Low latency requirements
- No embedding model needed

Consider dense retrieval for:

- Semantic similarity
- Paraphrase matching
- Multilingual queries
