# vLLM (OpenAI-compatible API)
# pip install langchain-openai
# Start vLLM server: vllm serve <model_name> --port 8000
_target_: langchain_openai.ChatOpenAI
model: ${oc.env:VLLM_MODEL_NAME,meta-llama/Llama-3.1-8B-Instruct}
base_url: ${oc.env:VLLM_API_BASE,http://localhost:8000/v1}
api_key: ${oc.env:VLLM_API_KEY,token-abc123}
